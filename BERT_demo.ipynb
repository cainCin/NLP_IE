{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo on BERT encoding and classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import torch\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "\n",
    "labels_path = \"/mnt/sda1/backup/lapCin/Workspace/Cinnamon/Data/Invoice/Phase 3/train/labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder:\n",
    "    _default = {\n",
    "            \"MODELS\": [(BertModel,       BertTokenizer,       'bert-base-uncased')\n",
    "         ],\n",
    "    }\n",
    "    def __init__(self):\n",
    "        self._set_default()\n",
    "        pass\n",
    "    \n",
    "    def _set_default(self):\n",
    "        for model_class, tokenizer_class, pretrained_weights in self._default[\"MODELS\"]:\n",
    "            # Load pretrained model/tokenizer\n",
    "            self.tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "            self.model = model_class.from_pretrained(pretrained_weights)\n",
    "    \n",
    "    def encode(self, text, special_tokens=True):\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text, add_special_tokens=special_tokens)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = self.model(input_ids)[0]  # Models outputs are now tuples\n",
    "        return last_hidden_states\n",
    "    \n",
    "    def compress(self, X, mode=\"average\"):\n",
    "        return X.mean(dim=1)\n",
    "    \n",
    "    def export_pd(self, X):\n",
    "        return pd.DataFrame(X)\n",
    "        \n",
    "    def process_text_list(self, text_list):\n",
    "        X = [self.encode(text) for text in text_list]\n",
    "        X = [self.compress(x) for x in X]\n",
    "        X = torch.cat(X, dim=0).numpy()\n",
    "        X = self.export_pd(X)\n",
    "        return X\n",
    "        \n",
    "    def process(self, data):\n",
    "        text_list = [text for (text, C) in data]\n",
    "        X = self.process_text_list(text_list)\n",
    "        category = [C for text, C in data]\n",
    "        \n",
    "        X[\"Class\"] = category\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def parse_json_to_CASIA(label_path):\n",
    "    CASIA_output = []\n",
    "    with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        for info in label['attributes']['_via_img_metadata']['regions']:\n",
    "            shape_info = info['shape_attributes']\n",
    "            item_info = info['region_attributes']\n",
    "            text = item_info.get('label')\n",
    "            formal_key = item_info.get('formal_key')\n",
    "            key_type = item_info.get('key_type')\n",
    "            try:\n",
    "                x,y,w,h = [shape_info['x'], shape_info['y'], shape_info['width'], shape_info['height']]\n",
    "                loc = [(x,y), (x+w,y), (x+w,y+h), (x,y+h)]\n",
    "            except:\n",
    "                loc = [(x,y) for (x,y) in zip(shape_info['all_points_x'], shape_info['all_points_y'])]\n",
    "            #print(f\"{text}: - KEY: {formal_key} - TYPE: {key_type} - LOC: {x,y,w,h}\")\n",
    "            \n",
    "            # put into CASIA\n",
    "            item = {\n",
    "                'text': text,\n",
    "                'type': formal_key,\n",
    "                'key_type': key_type,\n",
    "                'location': loc,\n",
    "            }\n",
    "            CASIA_output.append(item)\n",
    "    return CASIA_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "``` python\n",
    "labels_path = \"/mnt/sda1/backup/lapCin/Workspace/Cinnamon/Data/Invoice/Phase 3/train/labels\"\n",
    "list_label = glob.glob(labels_path + \"/*\")\n",
    "\n",
    "\n",
    "data = []\n",
    "for label_path in list_label:\n",
    "    print(f\"Processing {label_path}\")\n",
    "    CASIA_output = parse_json_to_CASIA(label_path)\n",
    "    item = [(item.get(\"text\"), item.get(\"type\")) for item in CASIA_output \\\n",
    "            if item.get(\"type\") not in [\"\", None, \"None\"]]\n",
    "    data.extend(item)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"Text dataset from json\"\"\"\n",
    "\n",
    "    def __init__(self, labels_path, category=None, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data, self.category = self.load_data(labels_path, category)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def load_data(self, labels_path, category=None):\n",
    "        list_label = glob.glob(labels_path + \"/*\")\n",
    "        data = []\n",
    "        for label_path in list_label:\n",
    "            #print(f\"Processing {label_path}\")\n",
    "            CASIA_output = parse_json_to_CASIA(label_path)\n",
    "            item = [(item.get(\"text\"), item.get(\"type\")) for item in CASIA_output \\\n",
    "                    if item.get(\"type\") not in [\"\", None, \"None\"] and item.get('key_type') in \"value\"]\n",
    "            if category:\n",
    "                out = []\n",
    "                for element in item:\n",
    "                    for cat in category:\n",
    "                        if cat in element[1]:\n",
    "                            out.append(element)\n",
    "                            continue\n",
    "                item = out\n",
    "\n",
    "            data.extend(item)\n",
    "        \n",
    "        category = list(np.unique([item[1] for item in data]))\n",
    "        \n",
    "        return data, category\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "      \n",
    "        text, cat = self.data[idx]\n",
    "        if self.transform:\n",
    "            text = self.transform(text)\n",
    "        if self.target_transform:\n",
    "            cat = self.target_transform(cat)\n",
    "            \n",
    "        return text, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [\"name\", \"date\", \"type\", \"quantity\", \"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _target_transform(label, category=category):\n",
    "    out = [cat in label for cat in category]\n",
    "    out = torch.tensor([out]).type(torch.FloatTensor)\n",
    "    return out\n",
    "\n",
    "def target_transform(label, category=category):\n",
    "    for cat in category:\n",
    "        if cat in label:\n",
    "            return cat\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "trainset = TextDataset(labels_path, category, target_transform=target_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account type',\n",
       " 'account_name',\n",
       " 'account_name_kana',\n",
       " 'account_type',\n",
       " 'amount_excluding_tax',\n",
       " 'amount_including_tax',\n",
       " 'amount_tax',\n",
       " 'amount_total_including_tax',\n",
       " 'bank_branch_name',\n",
       " 'bank_name',\n",
       " 'bank_name_bank_branch_name_account_name_account_type_account_number',\n",
       " 'branch_name',\n",
       " 'company name',\n",
       " 'company_name',\n",
       " 'delivery_date',\n",
       " 'destination_company_department_name',\n",
       " 'document_name',\n",
       " 'issued_date',\n",
       " 'item _unit_amount',\n",
       " 'item_name',\n",
       " 'item_quantity',\n",
       " 'item_quantity_item_unit',\n",
       " 'item_unit_amount',\n",
       " 'pay_com_name',\n",
       " 'payment_date']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category = ['account type',\n",
    " 'account_name',\n",
    " 'account_name_kana',\n",
    " 'account_number',\n",
    " 'account_type',\n",
    " 'amount_excluding_tax',\n",
    " 'amount_including_tax',\n",
    " 'amount_tax',\n",
    " 'bank_branch_name',\n",
    " 'bank_name',\n",
    " 'branch_address',\n",
    " 'branch_fax',\n",
    " 'branch_name',\n",
    " 'branch_tel',\n",
    " 'branch_zipcode',\n",
    " 'car_number',\n",
    " 'company address',\n",
    " 'company name',\n",
    " 'company_address',\n",
    " 'company_fax',\n",
    " 'company_name',\n",
    " 'company_tel',\n",
    " 'company_zipcode',\n",
    " 'delivery_date',\n",
    " 'document_name',\n",
    " 'document_number',\n",
    " 'invoice_number',\n",
    " 'issued_date',\n",
    " 'item_unit_amount',\n",
    " 'item_line_number',\n",
    " 'item_name',\n",
    " 'item_quantity',\n",
    " 'item_total_excluding_tax',\n",
    " 'item_total_including_tax',\n",
    " 'item_total_tax',\n",
    " 'item_unit',\n",
    " 'item_unit_amount',\n",
    " 'partner_code',\n",
    " 'pay_com_name',\n",
    " 'payment_date',\n",
    " 'table_excluding_tax',\n",
    " 'table_total_excluding_tax',\n",
    " 'table_total_including_tax',\n",
    " 'table_total_tax',\n",
    " 'tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest_text = '日本語（にほんご、にっぽんご[注 1]）は、主に日本国内や日本人同士の間で使用されている言語である。'\\nEM = TextEncoder()\\nencoded_text = EM.encode(test_text)\\nprint(test_text, encoded_text.shape)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_text = '日本語（にほんご、にっぽんご[注 1]）は、主に日本国内や日本人同士の間で使用されている言語である。'\n",
    "EM = TextEncoder()\n",
    "encoded_text = EM.encode(test_text)\n",
    "print(test_text, encoded_text.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "``` python\n",
    "BERT_MODEL_CLASSES = [BertForSequenceClassification, BertForTokenClassification]\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "for model_class in BERT_MODEL_CLASSES:\n",
    "    # Load pretrained model/tokenizer\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # Models can return full list of hidden-states & attentions weights at each layer\n",
    "    model = model_class.from_pretrained(pretrained_weights,\n",
    "                                        output_hidden_states=True,\n",
    "                                        output_attentions=True)\n",
    "    input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "    all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "\n",
    "    # Models are compatible with Torchscript\n",
    "    model = model_class.from_pretrained(pretrained_weights, torchscript=True)\n",
    "    traced_model = torch.jit.trace(model, (input_ids,))\n",
    "\n",
    "    # Simple serialization for models and tokenizers\n",
    "    model.save_pretrained('/mnt/sda1/code/weights/NLP')  # save\n",
    "    model = model_class.from_pretrained('/mnt/sda1/code/weights/NLP')  # re-load\n",
    "    tokenizer.save_pretrained('/mnt/sda1/code/weights/NLP')  # save\n",
    "    tokenizer = BertTokenizer.from_pretrained('/mnt/sda1/code/weights/NLP')  # re-load\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "class BERTSequenceClassfier:\n",
    "    def __init__(self, nClass=2):\n",
    "        self.model = BertForSequenceClassification.from_pretrained('/mnt/sda1/code/weights/NLP')\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('/mnt/sda1/code/weights/NLP')  # re-load\n",
    "        self.encode_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.nClass = nClass\n",
    "        self.design()\n",
    "        \n",
    "    def design(self):\n",
    "        # freeze model\n",
    "        for param in self.model.parameters(): param.requires_grad = False\n",
    "        # modifying last layer\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.nClass),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "        for param in self.model.classifier.parameters(): param.requires_grad = True\n",
    "        #print(self.model)\n",
    "    \n",
    "    def encode(self, text, special_tokens=True):\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text, add_special_tokens=special_tokens)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = self.encode_model(input_ids)[0]  # Models outputs are now tuples\n",
    "        return last_hidden_states\n",
    "    \n",
    "    def compress(self, X, mode=\"average\"):\n",
    "        return X.mean(dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, dataloader, nb_iter=100):\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.classifier.parameters(), lr=0.0001)\n",
    "        data_iter = iter(dataloader)\n",
    "        with tqdm.trange(nb_iter) as t:\n",
    "            for iteration in t:\n",
    "            #for texts, labels in dataloader:\n",
    "                try:\n",
    "                    texts, labels = next(data_iter)\n",
    "                except:\n",
    "                    data_iter = iter(dataloader)\n",
    "                    texts, labels = next(data_iter)\n",
    "                    \n",
    "                try:                  \n",
    "                    #print([self.tokenizer.encode(text, add_special_tokens=True) for text in texts])\n",
    "                    #break\n",
    "                    #input_ids = torch.tensor([self.tokenizer.encode(text, add_special_tokens=True) for text in texts])\n",
    "                    \n",
    "                    encode = self.encode(texts[0])\n",
    "                    input_ids = self.compress(encode)\n",
    "                    pred = self.model.classifier(input_ids)\n",
    "                    out = labels[0]\n",
    "                    #print(pred)\n",
    "                    #print(out)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #out = [cat in labels[0] for cat in category]\n",
    "                    \n",
    "                    \n",
    "                    #out = torch.tensor([out]).type(torch.FloatTensor)\n",
    "                    #print(pred)\n",
    "                    #print(out)\n",
    "                    loss = criterion(pred, out)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    t.set_description(f\"[{iteration}/{nb_iter}]: {loss.item()}\")\n",
    "                except:\n",
    "                    print(texts)\n",
    "                    continue\n",
    "            \n",
    "        \n",
    "    \n",
    "    def predict(self, text):\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text)])\n",
    "        #print(input_ids)\n",
    "        return self.model(input_ids)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERTclf = BERTSequenceClassfier(nClass=len(category))\n",
    "#BERTclf.train(trainloader, nb_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encode = BERTclf.encode(text)\n",
    "    input_ids = BERTclf.compress(encode)\n",
    "    return BERTclf.model.classifier(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_iter = iter(trainloader)\\ntest_text, label = test_iter.next()\\n#est_text = \\'日本語（にほんご、にっぽんご[注 1]）は、主に日本国内や日本人同士の間で使用されている言語である。\\'\\npred = predict(test_text[0])\\nprint(\"PRED:\", pred[0].detach())\\nidx = torch.argmax(pred[0].detach())\\nout = category[idx] if idx <len(category) else None\\nprint(test_text,out, label)\\nprint(category)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_iter = iter(trainloader)\n",
    "test_text, label = test_iter.next()\n",
    "#est_text = '日本語（にほんご、にっぽんご[注 1]）は、主に日本国内や日本人同士の間で使用されている言語である。'\n",
    "pred = predict(test_text[0])\n",
    "print(\"PRED:\", pred[0].detach())\n",
    "idx = torch.argmax(pred[0].detach())\n",
    "out = category[idx] if idx <len(category) else None\n",
    "print(test_text,out, label)\n",
    "print(category)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class BERTSVM:\n",
    "    def __init__(self, nClass=2):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('/mnt/sda1/code/weights/NLP')  # re-load\n",
    "        self.encode_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.nClass = nClass\n",
    "    \n",
    "    def export_pd(self, X):\n",
    "        return pd.DataFrame(X)\n",
    "\n",
    "    \n",
    "    def encode(self, text, special_tokens=True):\n",
    "        input_ids = torch.tensor([self.tokenizer.encode(text, add_special_tokens=special_tokens)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = self.encode_model(input_ids)[0]  # Models outputs are now tuples\n",
    "        return last_hidden_states\n",
    "    \n",
    "    def compress(self, X, mode=\"average\"):\n",
    "        return X.mean(dim=1)\n",
    "    \n",
    "    \n",
    "    def process_text_list(self, text_list):\n",
    "        X = []\n",
    "        for text in text_list:\n",
    "            try:\n",
    "                encode = self.encode(text)\n",
    "                x = self.compress(encode)\n",
    "                X.append(x)\n",
    "            except:\n",
    "                print(text)\n",
    "                \n",
    "        #X = [self.encode(text) for text in text_list]\n",
    "        #X = [self.compress(x) for x in X]\n",
    "        X = torch.cat(X, dim=0).numpy()\n",
    "        X = self.export_pd(X)\n",
    "        return X\n",
    "    \n",
    "    def process(self, data):\n",
    "        X = []\n",
    "        category = []\n",
    "        with tqdm.trange(len(data)) as t:\n",
    "            for iteration in t:\n",
    "            #for text, C in tqdm(data):\n",
    "                text, C = data[iteration]\n",
    "                try:\n",
    "                    encode = self.encode(text)\n",
    "                    x = self.compress(encode)\n",
    "                    X.append(x)\n",
    "                    category.append(C)\n",
    "                except:\n",
    "                    print(text)\n",
    "                \n",
    "        X = torch.cat(X, dim=0).numpy()\n",
    "        X = self.export_pd(X)                \n",
    "        X[\"Class\"] = category\n",
    "        return X\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, dataloader, nb_iter=100):\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    \n",
    "    def predict(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1422/9284 [00:29<02:35, 50.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9284/9284 [03:08<00:00, 49.21it/s]\n"
     ]
    }
   ],
   "source": [
    "out = BERTSVM().process(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class CLASSIFIER:\n",
    "    def __init__(self):\n",
    "        self.load_default_classifier()\n",
    "        pass\n",
    "    \n",
    "    def load_default_classifier(self):\n",
    "        self.load_svm()\n",
    "        \n",
    "    def load_svm(self, kernel='poly', degree=8):\n",
    "        self.model = SVC(kernel=kernel, degree=degree)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.probability = True\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def score(self, X):\n",
    "        return self.model._predict_proba(X)\n",
    "    \n",
    "    def score_log(self, X):\n",
    "        return self.model._predict_log_proba(X)\n",
    "    \n",
    "    def predict_MC(self, X):\n",
    "        self.decision_function_shape='ovr'\n",
    "        return self.model.decision_function(X)\n",
    "    \n",
    "class REPORT:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def export_report(self, gt, pred):\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def export_confusion_matrix(self, gt, pred):\n",
    "        print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split to data and label\n",
    "X = out.drop('Class', axis=1)\n",
    "y = out['Class']\n",
    "\n",
    "# Split train - test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356       type\n",
       "2682      name\n",
       "505       date\n",
       "4101      name\n",
       "4372    amount\n",
       "         ...  \n",
       "4555      date\n",
       "4680      name\n",
       "3944      date\n",
       "1484      name\n",
       "5385    amount\n",
       "Name: Class, Length: 7426, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 1.141756296157837 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      amount       0.99      0.98      0.98       379\n",
      "        date       1.00      0.98      0.99       324\n",
      "        name       0.98      0.99      0.99       904\n",
      "    quantity       0.95      0.90      0.93       104\n",
      "        type       0.94      0.97      0.96       146\n",
      "\n",
      "    accuracy                           0.98      1857\n",
      "   macro avg       0.97      0.97      0.97      1857\n",
      "weighted avg       0.98      0.98      0.98      1857\n",
      "\n",
      "[[372   0   2   5   0]\n",
      " [  0 317   7   0   0]\n",
      " [  0   0 895   0   9]\n",
      " [  5   0   5  94   0]\n",
      " [  0   0   4   0 142]]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "classifier = CLASSIFIER()\n",
    "classifier.fit(X_train, y_train)\n",
    "s = time()\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(f\"Elapsed {time()-s} s\")\n",
    "y_score = classifier.score(X_test)\n",
    "report = REPORT()\n",
    "report.export_report(y_test, y_pred)\n",
    "report.export_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    X = BERTSVM().process([(text, None)])\n",
    "    X = X.drop('Class', axis=1)\n",
    "    y = classifier.predict(X)\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 45.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quantity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"abc\"))\n",
    "print(predict(\"12/2/2020\"))\n",
    "print(predict(\"12\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 40.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"15.000.00\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
